{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b28f10",
   "metadata": {},
   "source": [
    "# Loading Historical CNPL Data (ZStructs) with the neuraldecoding Dataset class\n",
    "In this tutorial, you will learn the basics of loading data from the Chestek Lab with the Dataset class.\n",
    "Also, serves as a fairly standard intro to working with datasets\n",
    "\n",
    "First set up your imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import neuraldecoding.dataset as neuraldataset\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff9e0f",
   "metadata": {},
   "source": [
    "## Step 1. Config Files\n",
    "Like many things in neuraldecoding, we use a config file to define the parameters used to load a dataset. This is helpful for reproducibility, as you can use this config file as a record of what you ran (among other more robust logging features).\n",
    "\n",
    "This config file also has a standard format, so it can be integrated into larger yaml files as a subconfiguration.\n",
    "Every config file starts like this:\n",
    "\n",
    "```yaml\n",
    "dataset_type: <insert dataset type>\n",
    "autoload: <bool>\n",
    "save_path: null # or a filepath\n",
    "dataset_parameters:\n",
    "```\n",
    "\n",
    "This will be the same for all data types. `dataset_type` will be used to call the correct code for loading and reformating the dataset your want. In our case, we want to use `zstruct`. `dataset_parameters` contains indented entries with all the parameters needed for your particular dataset type. A standard `zstruct` config looks like this:\n",
    "\n",
    "```yaml\n",
    "dataset_type: zstruct\n",
    "autoload: True\n",
    "save_path: null\n",
    "dataset_parameters:\n",
    "  overwrite: True\n",
    "  experiment_type: monkey_emg_16_96\n",
    "  server_dir: Z:\\Data\\Monkeys\n",
    "  alt_filepath: null\n",
    "  subject: Joker\n",
    "  subject_id: \"Monkey N\"\n",
    "  date: 2024-06-06\n",
    "  run: 2\n",
    "```\n",
    "Let's load this config using OmegaConf (HYDRA EVENTUALLY?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "934e01fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_type': 'zstruct', 'autoload': True, 'save_path': None, 'dataset_parameters': {'overwrite': False, 'experiment_type': 'monkey_emg_16_96', 'server_dir': 'Z:\\\\Data\\\\Monkeys', 'alt_filepath': None, 'subject': 'Joker', 'subject_id': 'Monkey N', 'date': '2024-06-06', 'run': 2}}\n"
     ]
    }
   ],
   "source": [
    "sample_config_file = OmegaConf.load(\"..\\\\example_configs\\\\datasets\\\\xpc_monkey_EMG.yaml\")\n",
    "print(sample_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0b3b5",
   "metadata": {},
   "source": [
    "Now that is has been loaded, we can use it to create a dataset!\n",
    "\n",
    "## Step 2. Loading the data\n",
    "Once we've loaded a config file (or composed one in code) we can load a dataset as follows, using the config file as the parameters to the constructor. If `autoload` is `True`, then the data will automatically be loaded when this is run. Otherwise, we need to call `load_data()` on a separate line. In this config file, we've set `overwrite` to `True` so you can see the file being loaded, but if we've already created an NWB version of the zstruct, there's usually not a huge need to overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255584bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWB file already exists, loading\n"
     ]
    }
   ],
   "source": [
    "data = neuraldataset.Dataset(sample_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b4cd2",
   "metadata": {},
   "source": [
    "Now that we've loaded the data, we can have a look at it. Click on the arrows next to expand each module. The actual EMG and behavior data are saved in 'processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0035e495",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to synchronously get dataspace (identifier is not of specified type)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\IPython\\core\\formatters.py:406\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    404\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:676\u001b[39m, in \u001b[36mContainer._repr_html_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    674\u001b[39m html_repr += \u001b[33m\"\u001b[39m\u001b[33m<div class=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontainer-wrap\u001b[39m\u001b[33m'\u001b[39m\u001b[33m>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    675\u001b[39m html_repr += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<div class=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontainer-header\u001b[39m\u001b[33m'\u001b[39m\u001b[33m><div class=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mxr-obj-type\u001b[39m\u001b[33m'\u001b[39m\u001b[33m><h3>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheader_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</h3></div></div>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m html_repr += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_field\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    677\u001b[39m html_repr += \u001b[33m\"\u001b[39m\u001b[33m</div>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m html_repr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:690\u001b[39m, in \u001b[36mContainer._generate_html_repr\u001b[39m\u001b[34m(self, fields, level, access_code, is_field)\u001b[39m\n\u001b[32m    688\u001b[39m             html_repr += value._generate_field_html(key, value, level, current_access_code)\n\u001b[32m    689\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m             html_repr += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_field_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_access_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fields, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m index, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fields):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:725\u001b[39m, in \u001b[36mContainer._generate_field_html\u001b[39m\u001b[34m(self, key, value, level, access_code)\u001b[39m\n\u001b[32m    723\u001b[39m     html_content = \u001b[38;5;28mself\u001b[39m._generate_html_repr(value.fields, level + \u001b[32m1\u001b[39m, access_code, is_field=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m, np.ndarray)):\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     html_content = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccess_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_field\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    727\u001b[39m     html_content = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfield-key\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</span>\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:688\u001b[39m, in \u001b[36mContainer._generate_html_repr\u001b[39m\u001b[34m(self, fields, level, access_code, is_field)\u001b[39m\n\u001b[32m    686\u001b[39m current_access_code = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccess_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_field \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccess_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m[\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m'\u001b[39m\u001b[33m_generate_field_html\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m     html_repr += \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_generate_field_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_access_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    690\u001b[39m     html_repr += \u001b[38;5;28mself\u001b[39m._generate_field_html(key, value, level, current_access_code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\pynwb\\base.py:342\u001b[39m, in \u001b[36mTimeSeries._generate_field_html\u001b[39m\u001b[34m(self, key, value, level, access_code)\u001b[39m\n\u001b[32m    339\u001b[39m     linked_key = \u001b[33m'\u001b[39m\u001b[33mtimestamps\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[33m'\u001b[39m\u001b[33mtimestamp_link\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    340\u001b[39m     value = [find_location_in_memory_nwbfile(linked_key, v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_generate_field_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccess_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:723\u001b[39m, in \u001b[36mContainer._generate_field_html\u001b[39m\u001b[34m(self, key, value, level, access_code)\u001b[39m\n\u001b[32m    721\u001b[39m     html_content = value.__repr_html__()\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mfields\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# Note that h5py.Dataset has a fields attribute so there is an implicit order\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m     html_content = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccess_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_field\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m, np.ndarray)):\n\u001b[32m    725\u001b[39m     html_content = \u001b[38;5;28mself\u001b[39m._generate_html_repr(value, level + \u001b[32m1\u001b[39m, access_code, is_field=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:690\u001b[39m, in \u001b[36mContainer._generate_html_repr\u001b[39m\u001b[34m(self, fields, level, access_code, is_field)\u001b[39m\n\u001b[32m    688\u001b[39m             html_repr += value._generate_field_html(key, value, level, current_access_code)\n\u001b[32m    689\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m             html_repr += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_field_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_access_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fields, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m index, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fields):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\pynwb\\base.py:342\u001b[39m, in \u001b[36mTimeSeries._generate_field_html\u001b[39m\u001b[34m(self, key, value, level, access_code)\u001b[39m\n\u001b[32m    339\u001b[39m     linked_key = \u001b[33m'\u001b[39m\u001b[33mtimestamps\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[33m'\u001b[39m\u001b[33mtimestamp_link\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    340\u001b[39m     value = [find_location_in_memory_nwbfile(linked_key, v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_generate_field_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccess_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:717\u001b[39m, in \u001b[36mContainer._generate_field_html\u001b[39m\u001b[34m(self, key, value, level, access_code)\u001b[39m\n\u001b[32m    714\u001b[39m is_array_data = \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_array_data:\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     html_content = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_array_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[33m\"\u001b[39m\u001b[33mgenerate_html_repr\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    719\u001b[39m     html_content = value.generate_html_repr(level + \u001b[32m1\u001b[39m, access_code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\container.py:759\u001b[39m, in \u001b[36mContainer._generate_array_html\u001b[39m\u001b[34m(self, array, level)\u001b[39m\n\u001b[32m    753\u001b[39m     repr_html = generate_array_html_repr(array_info_dict, array.data, \u001b[33m\"\u001b[39m\u001b[33mDataIO\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m it_was_read_with_io:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# The backend handles the representation here. Two special cases worth noting:\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# 1. Array-type attributes (e.g., start_frame in ImageSeries) remain NumPy arrays\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m#    even when their parent container has an IO\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;66;03m# 2. Data may have been modified after being read from storage\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m     repr_html = \u001b[43mread_io\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_dataset_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Not sure which object could get here\u001b[39;00m\n\u001b[32m    761\u001b[39m     object_class = array.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\backends\\hdf5\\h5tools.py:1498\u001b[39m, in \u001b[36mHDF5IO.generate_dataset_html\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_dataset_html\u001b[39m(dataset):\n\u001b[32m   1496\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generates an html representation for a dataset for the HDF5IO class\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1498\u001b[39m     array_info_dict = \u001b[43mget_basic_array_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1499\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, h5py.Dataset):\n\u001b[32m   1500\u001b[39m         dataset_type = \u001b[33m\"\u001b[39m\u001b[33mHDF5 dataset\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\hdmf\\utils.py:907\u001b[39m, in \u001b[36mget_basic_array_info\u001b[39m\u001b[34m(array)\u001b[39m\n\u001b[32m    904\u001b[39m         i += \u001b[32m1\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbytes_size\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffixes[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnbytes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# TODO: Remove this after h5py minimal version is larger than 3.0\u001b[39;00m\n\u001b[32m    908\u001b[39m     array_size_in_bytes = array.nbytes\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\h5py\\_hl\\dataset.py:553\u001b[39m, in \u001b[36mDataset.nbytes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnbytes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    552\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Numpy-style attribute giving the raw dataset size as the number of bytes\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     size = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\n\u001b[32m    554\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# if we are an empty 0-D array, then there are no bytes in the dataset\u001b[39;00m\n\u001b[32m    555\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\h5py\\_hl\\dataset.py:539\u001b[39m, in \u001b[36mDataset.size\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cache_props:\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cache_props[\u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_is_empty\u001b[49m:\n\u001b[32m    540\u001b[39m     size = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\h5py\\_hl\\base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\h5py\\_hl\\dataset.py:684\u001b[39m, in \u001b[36mDataset._is_empty\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    682\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_empty\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    683\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check if extent type is empty\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extent_type\u001b[49m == h5s.NULL\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\h5py\\_hl\\base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hisham\\anaconda3\\envs\\neuraldecoding\\Lib\\site-packages\\h5py\\_hl\\dataset.py:679\u001b[39m, in \u001b[36mDataset._extent_type\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    675\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    676\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_extent_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    678\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get extent type for this dataset - SIMPLE, SCALAR or NULL\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get_simple_extent_type()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5d.pyx:374\u001b[39m, in \u001b[36mh5py.h5d.DatasetID.get_space\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to synchronously get dataspace (identifier is not of specified type)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "root pynwb.file.NWBFile at 0x2475913649840\n",
       "Fields:\n",
       "  acquisition: {\n",
       "    ParasiteTime <class 'pynwb.base.TimeSeries'>\n",
       "  }\n",
       "  devices: {\n",
       "    Cerebus <class 'pynwb.device.Device'>\n",
       "  }\n",
       "  electrode_groups: {\n",
       "    Wire Electrodes <class 'pynwb.ecephys.ElectrodeGroup'>\n",
       "  }\n",
       "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
       "  experimenter: ['']\n",
       "  file_create_date: [datetime.datetime(2025, 7, 15, 14, 37, 49, 54334, tzinfo=tzoffset(None, -14400))]\n",
       "  identifier: Z:\\Data\\Monkeys\\Joker\\2024-06-06/Run-002\n",
       "  institution: University of Michigan\n",
       "  intervals: {\n",
       "    trials <class 'pynwb.epoch.TimeIntervals'>\n",
       "  }\n",
       "  lab: Chestek Lab\n",
       "  notes: - Date: 06/06/2024\n",
       "\n",
       "- Goal: EMG decoding comparison with KF trained in March\n",
       "\n",
       "- Experimenters: Matt, Jake, Aren, Maddi\n",
       "- Recording Start Time: ~10:30 AM\n",
       "- Recording Stop Time:  AM\n",
       "\n",
       "- xPC Model: Rig_main_Cortical_Parasite_v2\n",
       "- Recorded Array: EMG\n",
       "- Data recorded: 2kSps 100-500HzBPass + broadband on cerebus, (also continuous on chans 17-96 recorded, but no signal connected)\n",
       "- Drink: Apple Juice\n",
       "\n",
       "- Params:\n",
       "\t* Movement Mask: [0,1,0,1,0]\n",
       "\t* Target Hold Time (OL/CL): 750 (hand control) / 500 (online)\n",
       "\t* Target Scaling(OL/CL): 100\n",
       "\t* Juice Time: 100\n",
       "\t* Trial Timeout: 10000\n",
       "\t* Auto Juice: 0\n",
       "   \t* Target Pos Style (OL/CL): 29\n",
       "\t* Visualization Style: MRS\n",
       "\t* Manipulandum: old\n",
       "\t* Repeat failure: off\n",
       "\t\n",
       "-Decoders:\n",
       "\n",
       "KF0: 6/6 Kalman Filter\n",
       "\tTrainOnline_Cortical_KalmanFilter_Multi('Joker','',2,false,[2 4],32,0,good_chans_EMG,good_chans_EMG,1,{'act_thresh',1},0,true);\n",
       "\t\tSBP KF correlation = 0.89219\n",
       "\t\tSBP KF lag = 1\n",
       "KF1: 3/26 Kalman Filter\n",
       "\t TrainOnline_Cortical_KalmanFilter_Multi('Joker','',2,false,[2 4],32,0,good_chans_EMG,good_chans_EMG,1,{'act_thresh',1},0,true);\n",
       "\t\tSBP KF correlation = 0.84857\n",
       "\t\tSBP KF lag = 2\n",
       "\t\t\n",
       "-Runs:\t\n",
       "\n",
       "\tRun 1: Warmup while we went back to human side - 75 trials, didn't really have a break after\n",
       "\tRun 2: TS29 training run, 400 trials\n",
       "\n",
       "\t-- 5 min break for model training--\n",
       "\t\n",
       "\tRun 3: KF0, TS29, 150 trials, BR ~2.83 at the end\n",
       "\tRun 4: KF1, TS29, 150 trials, BR ~2.88 at the end\n",
       "\tRun 5: KF0, TS29, 150 trials, BR ~3.17 at the end\n",
       "\tRun 6: KF1, TS29, 150 trials, BR ~2.91 at the end\n",
       "\tRun 7: KF0, TS29, 150 trials, BR ~2.80 at the end\n",
       "\tRun 8: KF1, TS29, 150 trials, BR ~3.08 at the end\n",
       "\t\n",
       "\n",
       "\t\n",
       "-Summary:\n",
       "\t- ran a ABABAB (KF0/KF1)\n",
       "\t- good_chans_EMG = [1,3,5,7,9,11,13,15]\n",
       "\t\n",
       "-Notes:\n",
       "\tVets came and took a look at headcap before the experiment\n",
       "  processing: {\n",
       "    behavior <class 'pynwb.base.ProcessingModule'>,\n",
       "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
       "  }\n",
       "  session_description: Z:\\Data\\Monkeys\\Joker\\2024-06-06 | Run-002\n",
       "  session_start_time: 2024-06-06 10:28:38.993672-04:00\n",
       "  subject: subject pynwb.file.Subject at 0x2475913704016\n",
       "Fields:\n",
       "  age__reference: birth\n",
       "  description: Joker\n",
       "  subject_id: Joker\n",
       "\n",
       "  timestamps_reference_time: 2024-06-06 10:28:38.993672-04:00\n",
       "  trials: trials <class 'pynwb.epoch.TimeIntervals'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c211a",
   "metadata": {},
   "source": [
    "## Step 3. Using the data\n",
    "Now we can use the data. A lot of this is still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8e0507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0000e-03, 3.0000e-03, 4.0000e-03, ..., 4.0007e+01, 4.0008e+01,\n",
       "       4.0009e+01], shape=(40000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = data.dataset.processing[\"ecephys\"][\"MAV\"].timestamps[:]\n",
    "aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuraldecoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
