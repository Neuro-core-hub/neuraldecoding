defaults:
  - /model@model: model

optimizer:
  type: Adam
  params:
    lr: 2e-4
    weight_decay: 0.001

scheduler:
  type: LinearLR
  params:
    start_factor: 1.0
    end_factor: 0.05 #1e-5 / 2e-4
    total_iters: 2000

loss_func:
  type: MSELoss
  params: {}

training:
  num_epochs: 2000
  batch_size: 64
  device: cuda # cuda , if avail 
  print_results: True
  print_every: 200
  clear_cache: False

evaluation:
  metrics: ["loss", "r2"]
  params:
    r2:
      multioutput: 'raw_values'

data:
  data_path: "/home/chesteklab/Code/Chang/LINK_dataset/001201/sub-Monkey-N/sub-Monkey-N_ses-20210628_ecephys.nwb"
  params:
    num_train_trials: 300
    sequence_length: ${trainer.model.params.sequence_length}
    split_ratio: 0.8
    split_seed: 42