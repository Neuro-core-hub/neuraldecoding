defaults:
  - /model@model: model

optimizer:
  type: Adam
  params:
    lr: 0.0002
    weight_decay: 0.001

scheduler:
  type: StepLR
  params:
    step_size: 50
    gamma: 0.4472

loss_func:
  type: MSELoss
  params: {}

training:
  num_epochs: 10
  batch_size: 64
  device: cuda # cuda , if avail 
  print_results: False
  print_every: 1
  clear_cache: False

evaluation:
  metrics: ["loss", "correlation"]
  params: {}

data:
  data_path: "D:/ND/github/LINK_dataset/data/001201/sub-Monkey-N/sub-Monkey-N_ses-20210628_ecephys.nwb"
  params:
    num_train_trials: 300
    sequence_length: ${trainer.model.params.sequence_length}
    split_ratio: 0.8
    split_seed: 42