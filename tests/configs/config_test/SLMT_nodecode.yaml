decoder:
  model: null
  fpath: lstm/lstm_date_{date}_day_{day}.pkl
trainer:
  model:
    type: SLMT
    params:
      input_size: 96
      num_outputs: 4
      hidden_size: 300
      num_layers: 1
      rnn_type: lstm
      device: cuda
      hidden_noise_std: 0.0
      dropout_input: false
      drop_prob: 0.0
      sequence_length: 20
  optimizer:
    type: Adam
    params:
      lr: 0.0002
      weight_decay: 0.001
  scheduler:
    type: LinearLR
    params:
      start_factor: 1.0
      end_factor: 0.05
      total_iters: 2000
  loss_func:
    type: MSELoss
    params: {}
  training:
    num_epochs: 2000
    batch_size: 64
    device: cuda
    print_results: true
    print_every: 200
    clear_cache: false
  evaluation:
    metrics:
    - loss
    - r2
    params:
      r2:
        multioutput: raw_values
  data:
    data_path: /home/chesteklab/Code/Chang/LINK_dataset/001201/sub-Monkey-N/sub-Monkey-N_ses-20210628_ecephys.nwb
    params:
      num_train_trials: 300
      sequence_length: ${trainer.model.params.sequence_length}
      split_ratio: 0.8
      split_seed: 42
preprocessing:
  preprocessing_trainer:
    order:
    - dict1
    - split1
    - tuple_out
    content:
      dict1:
        type: Dict2DataDictBlock
        params:
          neural_type: sbp
      split1:
        type: DataSplitBlock
        params:
          split_ratio: 0.9
          split_seed: -1
      tuple_out:
        type: Dict2TupleBlock
        params: {}
  preprocessing_decoder:
    order:
    - dict1
    - split1
    - add_history1
    - update_normalize_sequence
    - tensor1
    - tuple_out
    content:
      dict1:
        type: Dict2DataDictBlock
        params:
          neural_type: sbp
      split1:
        type: DataSplitBlock
        params:
          split_ratio: 0.9
          split_seed: -1
      add_history1:
        type: AddHistoryBlock
        params:
          location:
          - neural_train
          - neural_test
          seq_length: 20
      update_normalize_sequence:
        type: UpdateNormalizationBlock
        params:
          location:
          - neural_train
          - neural_test
          method: sequence_scaler
          normalizer_params:
            is_save: false
      tensor1:
        type: EnforceTensorBlock
        params:
          device: cuda
          dtype: float32
      tuple_out:
        type: Dict2TupleBlock
        params: {}
hash_id: da20a03a93f3d75ad3fd443b2d1126e2
